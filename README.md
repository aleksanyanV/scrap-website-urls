# Scrape website URLs

> Scrape website and get all URLs with statuses

## Getting started

```bash
# 1. Clone the repository.
git clone https://github.com/aleksanyanV/scrap-website-urls.git

# 2. Install dependencies.
yarn

# 3. Run project with website
yarn start https://example.website.com
```
